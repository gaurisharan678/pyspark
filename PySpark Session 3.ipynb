{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2a9f6e9c",
   "metadata": {},
   "source": [
    "Consider the dataset \"Operations Management\". Initiate a pyspark session and select the columns \"industry\" and \"values\" from dataset. Apply filter \"value\">200 and \"industry\"!=\"total\" to the dataframe created.\n",
    "Display first 5 rows of dataframe in descending. Also display schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d9953d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d42dbd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cf91370",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbbfc4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('dataframe').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cd5763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.format('csv').\\\n",
    "    option('inferSchema', 'true').\\\n",
    "    option('header', 'true').\\\n",
    "    option('path', 'operations_management.csv').\\\n",
    "    load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb123c78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\\n\\n# Define the schema for your CSV data\\ncustom_schema = StructType([\\n    StructField(\"description\", StringType(), True),  # Replace with your column names and data types\\n    StructField(\"industry\", StringType(), True),\\n    StructField(\"level\", IntegerType(), True),\\n    StructField(\"size\", StringType(), True),\\n    StructField(\"line_code\", StringType(), True),\\n    StructField(\"value\", IntegerType(), True),\\n\\n])\\n\\n# Replace \\'your_data.csv\\' with the path to your CSV file\\ndata = spark.read.csv(\"operations_management.csv\", schema=custom_schema, header=True)\\n\\n# Now you can work with your data\\ndata.show()\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if option == 'location' instead of 'path', we'll have to provide a custom\n",
    "#schema to read the file. setting location gives the error-\n",
    "#AnalysisException: [UNABLE_TO_INFER_SCHEMA] Unable to infer schema for CSV. \n",
    "#It must be specified manually.\n",
    "#here's the code for that-\n",
    "\n",
    "\"\"\"\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "# Define the schema for your CSV data\n",
    "custom_schema = StructType([\n",
    "    StructField(\"description\", StringType(), True),  # Replace with your column names and data types\n",
    "    StructField(\"industry\", StringType(), True),\n",
    "    StructField(\"level\", IntegerType(), True),\n",
    "    StructField(\"size\", StringType(), True),\n",
    "    StructField(\"line_code\", StringType(), True),\n",
    "    StructField(\"value\", IntegerType(), True),\n",
    "\n",
    "])\n",
    "\n",
    "# Replace 'your_data.csv' with the path to your CSV file\n",
    "data = spark.read.csv(\"operations_management.csv\", schema=custom_schema, header=True)\n",
    "\n",
    "# Now you can work with your data\n",
    "data.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83aeb14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+---------------+---------+-----+\n",
      "|         description|            industry|level|           size|line_code|value|\n",
      "+--------------------+--------------------+-----+---------------+---------+-----+\n",
      "|Awareness of clim...|               total|    0| 6–19 employees| C0300.01|13080|\n",
      "|Awareness of clim...|               total|    0|20–49 employees| C0300.01| 3348|\n",
      "|Awareness of clim...|               total|    0|50–99 employees| C0300.01| 1089|\n",
      "|Awareness of clim...|               total|    0| 100+ employees| C0300.01| 1023|\n",
      "|Awareness of clim...|Agriculture, fore...|    1|          total| C0300.01| 2364|\n",
      "|Awareness of clim...|         Agriculture|    2|          total| C0300.01| 1683|\n",
      "|Awareness of clim...|  Commercial fishing|    2|          total| C0300.01|   27|\n",
      "|Awareness of clim...|  Forestry & logging|    2|          total| C0300.01|  126|\n",
      "|Awareness of clim...|Agriculture, fore...|    2|          total| C0300.01|  528|\n",
      "|Awareness of clim...|              Mining|    1|          total| C0300.01|   72|\n",
      "|Awareness of clim...|       Manufacturing|    1|          total| C0300.01| 1971|\n",
      "|Awareness of clim...|Food, beverage, &...|    2|          total| C0300.01|  588|\n",
      "|Awareness of clim...|Textile, clothing...|    2|          total| C0300.01|   96|\n",
      "|Awareness of clim...|Wood & paper product|    2|          total| C0300.01|  156|\n",
      "|Awareness of clim...|Printing, publish...|    2|          total| C0300.01|   72|\n",
      "|Awareness of clim...|Petroleum, coal, ...|    2|          total| C0300.01|  189|\n",
      "|Awareness of clim...|Non-metallic mine...|    2|          total| C0300.01|  108|\n",
      "|Awareness of clim...|       Metal product|    2|          total| C0300.01|  246|\n",
      "|Awareness of clim...|Transport and ind...|    2|          total| C0300.01|  285|\n",
      "|Awareness of clim...|Other machinery &...|    2|          total| C0300.01|  117|\n",
      "+--------------------+--------------------+-----+---------------+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07cee915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- description: string (nullable = true)\n",
      " |-- industry: string (nullable = true)\n",
      " |-- level: integer (nullable = true)\n",
      " |-- size: string (nullable = true)\n",
      " |-- line_code: string (nullable = true)\n",
      " |-- value: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c76e0e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = data.select('industry', 'value').\\\n",
    "filter((col('value')>200) & (col('industry')!='total')).\\\n",
    "orderBy(desc('value'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0a86e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            industry|value|\n",
      "+--------------------+-----+\n",
      "|        Construction| 6030|\n",
      "|        Construction| 5904|\n",
      "|        Construction| 5229|\n",
      "|Accommodation & f...| 5058|\n",
      "|        Construction| 4965|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c02436f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- industry: string (nullable = true)\n",
      " |-- value: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_1.printSchema()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dab11919",
   "metadata": {},
   "source": [
    "Now take 'industry' = 'auxiliary' and 'value' < 30\n",
    "Display first 10 rows in ascending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19540a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = data.select('industry', 'value').\\\n",
    "filter((col('value')<30) & (col('industry')=='Auxiliary')).\\\n",
    "orderBy('value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bef0df8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "| industry|value|\n",
      "+---------+-----+\n",
      "|Auxiliary|    0|\n",
      "|Auxiliary|    0|\n",
      "|Auxiliary|    0|\n",
      "|Auxiliary|    0|\n",
      "|Auxiliary|    0|\n",
      "|Auxiliary|    0|\n",
      "|Auxiliary|    0|\n",
      "|Auxiliary|    3|\n",
      "|Auxiliary|    3|\n",
      "|Auxiliary|    3|\n",
      "+---------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_2.show(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c5091552",
   "metadata": {},
   "source": [
    "now run this using sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ee79414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#session scoped - temporary dataframe\n",
    "#dont give extension here\n",
    "data.createOrReplaceTempView(\"operations_management\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcf26192",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3 = spark.sql(\"\"\"\n",
    "select industry, value from operations_management\n",
    "where industry = 'Auxiliary' and value < 30\n",
    "order by value;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87bbe51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "| industry|value|\n",
      "+---------+-----+\n",
      "|Auxiliary|    0|\n",
      "|Auxiliary|    0|\n",
      "|Auxiliary|    0|\n",
      "|Auxiliary|    0|\n",
      "|Auxiliary|    0|\n",
      "|Auxiliary|    0|\n",
      "|Auxiliary|    0|\n",
      "|Auxiliary|    3|\n",
      "|Auxiliary|    3|\n",
      "|Auxiliary|    3|\n",
      "+---------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_3.show(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e7302455",
   "metadata": {},
   "source": [
    "attempt the first question using sql-\n",
    "\n",
    "Consider the dataset \"Operations Management\". Initiate a pyspark session and select the columns \"industry\" and \"values\" from dataset. Apply filter \"value\">200 and \"industry\"!=\"total\" to the dataframe created.\n",
    "Display first 5 rows of dataframe in descending. Also display schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4e49c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4 = spark.sql(\"\"\"\n",
    "select industry, value from operations_management\n",
    "where industry != 'total' and value > 200\n",
    "order by value desc;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe488f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            industry|value|\n",
      "+--------------------+-----+\n",
      "|        Construction| 6030|\n",
      "|        Construction| 5904|\n",
      "|        Construction| 5229|\n",
      "|Accommodation & f...| 5058|\n",
      "|        Construction| 4965|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_4.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00e921a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- industry: string (nullable = true)\n",
      " |-- value: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feb606a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
